{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get the argmax of each prediction list from list of lists and count matches, then print the accuracy\n",
    "def calcPerc(test_pred, y_test_dt):\n",
    "    true_count = 0\n",
    "    false_count = 0\n",
    "    count = -1\n",
    "    for x in test_pred:\n",
    "        max_index = np.argmax(x)\n",
    "        count += 1\n",
    "        if max_index == 0 and y_test_dt.iloc[count].values == 'neutral':\n",
    "            true_count += 1\n",
    "        elif max_index == 1 and y_test_dt.iloc[count].values == 'positive':\n",
    "            true_count += 1\n",
    "        elif max_index == 2 and y_test_dt.iloc[count].values == 'negative':\n",
    "            true_count += 1\n",
    "        else:\n",
    "            false_count += 1\n",
    "    print('Number of correct predictions: ' + str(true_count))\n",
    "    print('Number of false predictions: ' + str(false_count))\n",
    "    print('Test accuracy: ' + str(100*true_count/(true_count+false_count)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read training csv files and the txt file\n",
    "nms_frq = pd.read_csv('question-4-vocab.txt', header=None, sep='\\t', names=['names', 'freqs'])\n",
    "x_train = pd.read_csv('question-4-train-features.csv', header=None, sep=',', names=nms_frq['names'])\n",
    "y_train = pd.read_csv('question-4-train-labels.csv', header=None, sep=',', names=['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate features and labels for easy grouping\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "# set prior probabilities\n",
    "# get the negative priors for each word\n",
    "neg_prior = train.loc[train['results'] == 'negative'].select_dtypes(pd.np.number).sum().rename('total_neg')\n",
    "# get the positive priors\n",
    "pos_prior = train.loc[train['results'] == 'positive'].select_dtypes(pd.np.number).sum().rename('total_pos')\n",
    "# get the neutral priors\n",
    "ntr_prior = train.loc[train['results'] == 'neutral'].select_dtypes(pd.np.number).sum().rename('total_ntr')\n",
    "\n",
    "total_prior = x_train.select_dtypes(pd.np.number).sum().rename('total_prior')\n",
    "\n",
    "# get the total number of words in each res=neg/pos/ntr matrix\n",
    "total_pos_word_cnt = train.loc[train['results'] == 'positive'].select_dtypes(pd.np.number).values.sum()\n",
    "total_neg_word_cnt = train.loc[train['results'] == 'negative'].select_dtypes(pd.np.number).values.sum()\n",
    "total_ntr_word_cnt = train.loc[train['results'] == 'neutral'].select_dtypes(pd.np.number).values.sum()\n",
    "\n",
    "# get prior probabilities of labels\n",
    "pr_prob_pos = train.loc[train['results'] == 'positive'].shape[0] / x_train.shape[0]\n",
    "pr_prob_neg = train.loc[train['results'] == 'negative'].shape[0] / x_train.shape[0]\n",
    "pr_prob_ntr = 1 - (pr_prob_pos + pr_prob_neg)\n",
    "\n",
    "# get the ln for each label prior (used in a lot of calculations)\n",
    "pr_prob_pos_ln = np.log(pr_prob_pos)\n",
    "pr_prob_neg_ln = np.log(pr_prob_neg)\n",
    "pr_prob_ntr_ln = np.log(pr_prob_ntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative tweets in the training data: 7091\n",
      "Total number of tweets: 11712\n",
      "Percentage of negative tweets: 0.6054474043715847\n"
     ]
    }
   ],
   "source": [
    "neg_matrix = train.loc[train['results'] == 'negative']\n",
    "print('Number of negative tweets in the training data: ' + str(neg_matrix.shape[0]))\n",
    "print('Total number of tweets: ' + str(train.shape[0]))\n",
    "print('Percentage of negative tweets: ' + str(neg_matrix.shape[0]/train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read csv files for test data\n",
    "x_test = pd.read_csv('question-4-test-features.csv', header=None, sep=',', names=nms_frq['names'])\n",
    "y_test = pd.read_csv('question-4-test-labels.csv', header=None, sep=',', names=['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# calculate the probabilities for each word in any label\n",
    "neg_prior_prb = np.log(neg_prior/total_neg_word_cnt)\n",
    "pos_prior_prb = np.log(pos_prior/total_pos_word_cnt)\n",
    "ntr_prior_prb = np.log(ntr_prior/total_ntr_word_cnt)\n",
    "\n",
    "# run the prediction for each test sample\n",
    "mle_test_prediction = [[None for y in range(3)] for x in range(y_test.shape[0])]\n",
    "count_y_ntr = 0\n",
    "count_y_pos = 1\n",
    "count_y_neg = 2\n",
    "count_x = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    row = x_test.iloc[i]\n",
    "    temp_pos = pos_prior_prb * row.values  \n",
    "    temp_pos = pr_prob_pos_ln + np.sum(temp_pos.fillna(0))\n",
    "    temp_neg = neg_prior_prb * row.values\n",
    "    temp_neg = pr_prob_neg_ln + np.sum(temp_neg.fillna(0))\n",
    "    temp_ntr = ntr_prior_prb * row.values\n",
    "    temp_ntr = pr_prob_ntr_ln + np.sum(temp_ntr.fillna(0))\n",
    "    mle_test_prediction[count_x][count_y_ntr] = temp_ntr\n",
    "    mle_test_prediction[count_x][count_y_pos] = temp_pos\n",
    "    mle_test_prediction[count_x][count_y_neg] = temp_neg\n",
    "    count_x += 1              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 1839\n",
      "Number of false predictions: 1089\n",
      "Test accuracy: 62.807377049180324%\n"
     ]
    }
   ],
   "source": [
    "calcPerc(mle_test_prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate the probabilities for each word in any label given alpha = 1\n",
    "alpha = 1\n",
    "neg_prior_prb = np.log((neg_prior+alpha)/(total_neg_word_cnt+(alpha*x_train.shape[1])))\n",
    "pos_prior_prb = np.log((pos_prior+alpha)/(total_pos_word_cnt+(alpha*x_train.shape[1])))\n",
    "ntr_prior_prb = np.log((ntr_prior+alpha)/(total_ntr_word_cnt+(alpha*x_train.shape[1])))\n",
    "\n",
    "# run the prediction for each test sample\n",
    "map_test_prediction = [[None for y in range(3)] for x in range(y_test.shape[0])]\n",
    "count_y_ntr = 0\n",
    "count_y_pos = 1\n",
    "count_y_neg = 2\n",
    "count_x = 0\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    row = x_test.iloc[i]\n",
    "    temp_pos = pos_prior_prb * row.values  \n",
    "    temp_pos = pr_prob_pos_ln + np.sum(temp_pos.fillna(0))\n",
    "    temp_neg = neg_prior_prb * row.values\n",
    "    temp_neg = pr_prob_neg_ln + np.sum(temp_neg.fillna(0))\n",
    "    temp_ntr = ntr_prior_prb * row.values\n",
    "    temp_ntr = pr_prob_ntr_ln + np.sum(temp_ntr.fillna(0))\n",
    "    map_test_prediction[count_x][count_y_ntr] = temp_ntr\n",
    "    map_test_prediction[count_x][count_y_pos] = temp_pos\n",
    "    map_test_prediction[count_x][count_y_neg] = temp_neg\n",
    "    count_x += 1              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 2205\n",
      "Number of false predictions: 723\n",
      "Test accuracy: 75.30737704918033%\n"
     ]
    }
   ],
   "source": [
    "calcPerc(map_test_prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert training data to 1/0s for the bernoulli classifier\n",
    "x_train_br = x_train.copy()\n",
    "x_train_br[x_train_br != 0] = 1\n",
    "\n",
    "# concatenate features and labels for easy grouping\n",
    "train_br = pd.concat([x_train_br, y_train], axis=1)\n",
    "\n",
    "# set prior probabilities\n",
    "# get the negative priors for each word\n",
    "neg_prior_br = train_br.loc[train['results'] == 'negative'].select_dtypes(pd.np.number).sum().rename('total_neg')\n",
    "# get the positive priors\n",
    "pos_prior_br = train_br.loc[train['results'] == 'positive'].select_dtypes(pd.np.number).sum().rename('total_pos')\n",
    "# get the neutral priors\n",
    "ntr_prior_br = train_br.loc[train['results'] == 'neutral'].select_dtypes(pd.np.number).sum().rename('total_ntr')\n",
    "\n",
    "total_prior_br = x_train_br.select_dtypes(pd.np.number).sum().rename('total_prior')\n",
    "\n",
    "# total number of pos/neg/ntr tweets\n",
    "total_pos_tweets = train_br.loc[train['results'] == 'positive'].shape[0]\n",
    "total_neg_tweets = train_br.loc[train['results'] == 'negative'].shape[0]\n",
    "total_ntr_tweets = train_br.loc[train['results'] == 'neutral'].shape[0]\n",
    "\n",
    "# get prior probabilities of labels\n",
    "pr_prob_pos_br = train_br.loc[train['results'] == 'positive'].shape[0] / x_train_br.shape[0]\n",
    "pr_prob_neg_br = train_br.loc[train['results'] == 'negative'].shape[0] / x_train_br.shape[0]\n",
    "pr_prob_ntr_br = 1 - (pr_prob_pos + pr_prob_neg)\n",
    "\n",
    "# get the ln for each label prior (used in a lot of calculations)\n",
    "pr_prob_pos_ln = np.log(pr_prob_pos_br)\n",
    "pr_prob_neg_ln = np.log(pr_prob_neg_br)\n",
    "pr_prob_ntr_ln = np.log(pr_prob_ntr_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "# transform the test features to 1/0s\n",
    "x_test_br = x_test.copy()\n",
    "x_test_br[x_test_br != 0] = 1\n",
    "\n",
    "#calcluate the probabilities for each word and also their compliments\n",
    "neg_prior_prb = neg_prior_br/total_neg_tweets\n",
    "pos_prior_prb = pos_prior_br/total_pos_tweets\n",
    "ntr_prior_prb = ntr_prior_br/total_ntr_tweets\n",
    "neg_prior_prb_cmp = 1-neg_prior_prb\n",
    "pos_prior_prb_cmp = 1-pos_prior_prb\n",
    "ntr_prior_prb_cmp = 1-ntr_prior_prb\n",
    "\n",
    "#run the prediction for each test sample\n",
    "mle_test_prediction_br = [[None for y in range(3)] for x in range(y_test.shape[0])]\n",
    "count_y_ntr = 0\n",
    "count_y_pos = 1\n",
    "count_y_neg = 2\n",
    "count_x = 0\n",
    "for i in range(x_test_br.shape[0]):\n",
    "    row = x_test_br.iloc[i]\n",
    "    row_cmp = 1 - row\n",
    "    temp_pos = pos_prior_prb * row.values + pos_prior_prb_cmp * row_cmp.values\n",
    "    temp_pos = pr_prob_pos_ln + np.sum(np.log(temp_pos.fillna(0)))\n",
    "    temp_neg = neg_prior_prb * row.values + neg_prior_prb_cmp * row_cmp.values\n",
    "    temp_neg = pr_prob_neg_ln + np.sum(np.log(temp_neg.fillna(0)))\n",
    "    temp_ntr = ntr_prior_prb * row.values + ntr_prior_prb_cmp * row_cmp.values\n",
    "    temp_ntr = pr_prob_ntr_ln + np.sum(np.log(temp_ntr.fillna(0)))\n",
    "    mle_test_prediction_br[count_x][count_y_ntr] = temp_ntr\n",
    "    mle_test_prediction_br[count_x][count_y_pos] = temp_pos\n",
    "    mle_test_prediction_br[count_x][count_y_neg] = temp_neg\n",
    "    count_x += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 1878\n",
      "Number of false predictions: 1050\n",
      "Test accuracy: 64.13934426229508%\n"
     ]
    }
   ],
   "source": [
    "calcPerc(mle_test_prediction_br,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Most Commonly Used Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most commonly used words in positive tweets:\n",
      "@southwestair     573\n",
      "@jetblue          545\n",
      "@united           500\n",
      "flight            331\n",
      "@usairways        248\n",
      "great             205\n",
      "@virginamerica    152\n",
      "service           133\n",
      "love              116\n",
      "best               95\n",
      "guys               93\n",
      "customer           92\n",
      "time               87\n",
      "awesome            86\n",
      "help               71\n",
      "airline            71\n",
      "amazing            69\n",
      "today              68\n",
      "fly                62\n",
      "flying             61\n",
      "Name: total_pos, dtype: int64\n",
      "Most commonly used words in negative tweets:\n",
      "@united          2671\n",
      "flight           2270\n",
      "@usairways       2163\n",
      "@southwestair    1209\n",
      "@jetblue          963\n",
      "cancelled         620\n",
      "service           571\n",
      "hours             484\n",
      "hold              482\n",
      "time              480\n",
      "customer          466\n",
      "help              439\n",
      "delayed           436\n",
      "plane             429\n",
      "hour              378\n",
      "flights           334\n",
      "bag               326\n",
      "gate              321\n",
      "late              305\n",
      "flightled         290\n",
      "Name: total_neg, dtype: int64\n",
      "Most commonly used words in neutral tweets:\n",
      "@jetblue          706\n",
      "@united           701\n",
      "@southwestair     667\n",
      "flight            495\n",
      "@usairways        368\n",
      "@virginamerica    175\n",
      "flights           144\n",
      "help              133\n",
      "fleek             107\n",
      "fleet's           102\n",
      "dm                 99\n",
      "time               83\n",
      "tomorrow           83\n",
      "flying             71\n",
      "cancelled          66\n",
      "fly                65\n",
      "change             64\n",
      "today              61\n",
      "travel             61\n",
      "check              60\n",
      "Name: total_ntr, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Most commonly used words in positive tweets:')\n",
    "print(pos_prior.nlargest(n=20,keep='all'))\n",
    "print('Most commonly used words in negative tweets:')\n",
    "print(neg_prior.nlargest(n=20,keep='all'))\n",
    "print('Most commonly used words in neutral tweets:')\n",
    "print(ntr_prior.nlargest(n=20,keep='all'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
